{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install minio delta-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_date, date_format\n",
    "from delta.tables import *\n",
    "\n",
    "MINIO_ACCESS_KEY = \"PcgZbNx45AVgJG7mFksV\"\n",
    "MINIO_SECRET_KEY = \"MaWaeV659ur8MoTJukMlxe5tXK6cch5yVMLJ2Cuy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"MyAppMinio\") \\\n",
    "    .config(\"spark.eventLog.enabled\", \"true\") \\\n",
    "    .config(\"spark.eventLog.dir\", \"file:/home/jovyan/work/spark-logs\") \\\n",
    "    .config(\"spark.history.fs.logDirectory\", \"file:/home/jovyan/work/spark-logs\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"log4j.rootCategory\", \"INFO, console\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,io.delta:delta-core_2.12:2.4.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = spark.sparkContext\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", MINIO_ACCESS_KEY)\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", MINIO_SECRET_KEY)\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "# sc._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "# sc._jsc.hadoopConfiguration().set(\"log4j.logger.org.apache.hadoop.fs.s3a\", \"DEBUG\")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", MINIO_ACCESS_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", MINIO_SECRET_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "hadoop_conf.set(\"fs.s3a.path.style.access\", \"true\")\n",
    "hadoop_conf.set(\"fs.s3a.connection.ssl.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Teste conexão do ambiente do Jupyter com MINIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Minio(\n",
    "    \"minio:9000\",\n",
    "    access_key=MINIO_ACCESS_KEY,\n",
    "    secret_key=MINIO_SECRET_KEY,\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "for b in client.list_buckets():\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Teste a leitura do Spark com MINIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_bucket_stage = \"stage\"\n",
    "data_origem = f\"s3a://{minio_bucket_stage}/hotel_booking.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(data_origem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.select(['hotel', 'children', 'country']).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Teste de escrita no MINIO utilizando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de gravação em um bucket MinIO\n",
    "df = spark.createDataFrame([(1, \"apple\"), (2, \"banana\"), (3, \"laranja\")], [\"id\", \"fruit\"])\n",
    "df.write.format(\"parquet\").mode(\"overwrite\").save(\"s3a://bronze/test/data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo de volta\n",
    "df_loaded = spark.read.format(\"parquet\").load(\"s3a://bronze/test/data.parquet\")\n",
    "df_loaded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Escrevendo nossa primeira Delta Table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_bucket_bronze = \"bronze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de gravação em um bucket MinIO\n",
    "df = spark.createDataFrame([(1, \"apple\"), (2, \"banana\"), (3, \"laranja\")], [\"id\", \"fruit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('anomesdia', date_format(current_date(), 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravação no formato Delta\n",
    "df \\\n",
    "    .write \\\n",
    "    .format(\"delta\") \\\n",
    "    .partitionBy(\"anomesdia\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"s3a://{minio_bucket_bronze}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.withColumn('anomesdia', date_format(current_date(), 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravação no formato Delta\n",
    "data_df.write.format(\"delta\") \\\n",
    "    .partitionBy(\"anomesdia\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(f\"s3a://{minio_bucket_bronze}/delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = spark.read.format('delta').load(f\"s3a://{minio_bucket_bronze}/delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_delta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto DeltaTable\n",
    "delta_table = DeltaTable.forPath(spark, f\"s3a://{minio_bucket_bronze}/delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar o histórico da tabela\n",
    "history_df = delta_table.history()\n",
    "history_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
